# -*- coding: utf-8 -*-
"""Devoir 1/ASS 1/ Rapport.md.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1E5kAfzRfv1DiYzHB0Wdwe0w9hCMqzXkq
"""

pip install ucimlrepo

from ucimlrepo import fetch_ucirepo

# fetch dataset
student_performance = fetch_ucirepo(id=320)

# data (as pandas dataframes)
X = student_performance.data.features
y = student_performance.data.targets

# metadata
print(student_performance.metadata)

# variable information
print(student_performance.variables)

# üìö Analyse Compl√®te du Dataset "Student Performance"

**Source :** UCI Machine Learning Repository
**URL :** https://archive.ics.uci.edu/dataset/320/student+performance
**Cr√©ateur :** Paulo Cortez (Universit√© de Minho, Portugal)
**Date de publication :** 26 novembre 2014
**DOI :** 10.24432/C5TG7T
**Licence :** Creative Commons Attribution 4.0 International (CC BY 4.0)

---

## üìã Table des Mati√®res

1. [Vue d'Ensemble](#vue-densemble)
2. [Structure du Dataset](#structure-du-dataset)
3. [Description des 33 Variables](#description-des-33-variables)
4. [Cas d'Usage et Applications](#cas-dusage-et-applications)
5. [Analyses Possibles](#analyses-possibles)
6. [Insights et Hypoth√®ses](#insights-et-hypoth√®ses)
7. [Guide Pratique d'Utilisation](#guide-pratique-dutilisation)
8. [Analyses Exploratoires](#analyses-exploratoires)
9. [Contexte Acad√©mique](#contexte-acad√©mique)
10. [Consid√©rations Techniques](#consid√©rations-techniques)

---

## üìã Vue d'Ensemble

### Description G√©n√©rale

Ce dataset porte sur la **performance des √©tudiants dans l'enseignement secondaire** (lyc√©e) de deux √©coles portugaises. Il vise √† pr√©dire les r√©sultats acad√©miques des √©l√®ves en fonction de facteurs d√©mographiques, sociaux et scolaires.

### Caract√©ristiques Cl√©s

| Caract√©ristique | Valeur |
|-----------------|--------|
| **Type de dataset** | Multivari√© |
| **Domaine** | Sciences Sociales |
| **T√¢ches associ√©es** | Classification, R√©gression |
| **Type de features** | Entier, Cat√©goriel, Binaire |
| **Nombre d'instances** | 649 √©tudiants |
| **Nombre de features** | 33 attributs (30 features + 3 notes) |
| **Valeurs manquantes** | Non (0%) |
| **Taille du fichier** | 20 KB (student.zip) |

### Origine des Donn√©es

Les donn√©es ont √©t√© collect√©es via :
- **Rapports scolaires officiels** (bulletins de notes)
- **Questionnaires** remplis par les √©tudiants

Les √©coles concern√©es :
- **GP** - Gabriel Pereira
- **MS** - Mousinho da Silveira

---

## üìä Structure du Dataset

### Deux Datasets Distincts

Le dataset est divis√© en **deux fichiers s√©par√©s** :

1. **student-mat.csv** - Performance en **Math√©matiques**
2. **student-por.csv** - Performance en **Portugais** (langue)

Chaque fichier contient les m√™mes 33 attributs mais pour des mati√®res diff√©rentes.

### Variables Cibles (Target)

Les variables √† pr√©dire sont les **notes finales** :

- **G1** - Note de la 1√®re p√©riode (0-20)
- **G2** - Note de la 2√®me p√©riode (0-20)
- **G3** - Note finale de l'ann√©e (0-20) ‚≠ê **CIBLE PRINCIPALE**

**‚ö†Ô∏è Note importante :** G3 a une forte corr√©lation avec G1 et G2 (puisque G3 est la note finale incluant les p√©riodes pr√©c√©dentes). Il est plus difficile mais beaucoup plus utile de pr√©dire G3 sans utiliser G1 et G2.

---

## üîç Description des 33 Variables

### 1Ô∏è‚É£ Informations Scolaires (2 variables)

| Variable | Type | Description | Valeurs possibles |
|----------|------|-------------|-------------------|
| **school** | Cat√©goriel | √âcole de l'√©tudiant | 'GP' (Gabriel Pereira) ou 'MS' (Mousinho da Silveira) |
| **reason** | Cat√©goriel | Raison du choix de l'√©cole | 'home' (proximit√©), 'reputation', 'course' (programme), 'other' |

### 2Ô∏è‚É£ Informations D√©mographiques (4 variables)

| Variable | Type | Description | Valeurs possibles |
|----------|------|-------------|-------------------|
| **sex** | Binaire | Sexe de l'√©tudiant | 'F' (f√©minin) ou 'M' (masculin) |
| **age** | Num√©rique | √Çge de l'√©tudiant | 15 √† 22 ans |
| **address** | Binaire | Type d'adresse | 'U' (urbain) ou 'R' (rural) |
| **famsize** | Binaire | Taille de la famille | 'LE3' (‚â§3 personnes) ou 'GT3' (>3 personnes) |

### 3Ô∏è‚É£ Contexte Familial (6 variables)

| Variable | Type | Description | Valeurs possibles |
|----------|------|-------------|-------------------|
| **Pstatus** | Binaire | Statut de cohabitation des parents | 'T' (ensemble) ou 'A' (s√©par√©s) |
| **Medu** | Num√©rique | √âducation de la m√®re | 0 (aucune) √† 4 (sup√©rieure) |
| **Fedu** | Num√©rique | √âducation du p√®re | 0 (aucune) √† 4 (sup√©rieure) |
| **Mjob** | Cat√©goriel | Emploi de la m√®re | 'teacher', 'health', 'services', 'at_home', 'other' |
| **Fjob** | Cat√©goriel | Emploi du p√®re | 'teacher', 'health', 'services', 'at_home', 'other' |
| **guardian** | Cat√©goriel | Tuteur de l'√©tudiant | 'mother', 'father', 'other' |

**√âchelle d'√©ducation parentale :**
- 0 = Aucune √©ducation
- 1 = √âducation primaire (4th grade)
- 2 = 5√®me √† 9√®me ann√©e
- 3 = √âducation secondaire
- 4 = √âducation sup√©rieure (universit√©)

### 4Ô∏è‚É£ Temps et D√©placements (2 variables)

| Variable | Type | Description | Valeurs possibles |
|----------|------|-------------|-------------------|
| **traveltime** | Num√©rique | Temps de trajet domicile-√©cole | 1 (<15 min), 2 (15-30 min), 3 (30-60 min), 4 (>60 min) |
| **studytime** | Num√©rique | Temps d'√©tude hebdomadaire | 1 (<2h), 2 (2-5h), 3 (5-10h), 4 (>10h) |

### 5Ô∏è‚É£ Support √âducatif (4 variables)

| Variable | Type | Description | Valeurs possibles |
|----------|------|-------------|-------------------|
| **failures** | Num√©rique | Nombre d'√©checs scolaires pass√©s | 0, 1, 2, 3, ou 4 (‚â•3 √©checs) |
| **schoolsup** | Binaire | Support √©ducatif suppl√©mentaire de l'√©cole | 'yes' ou 'no' |
| **famsup** | Binaire | Support √©ducatif familial | 'yes' ou 'no' |
| **paid** | Binaire | Cours payants suppl√©mentaires (maths/portugais) | 'yes' ou 'no' |

### 6Ô∏è‚É£ Activit√©s et Ambitions (3 variables)

| Variable | Type | Description | Valeurs possibles |
|----------|------|-------------|-------------------|
| **activities** | Binaire | Activit√©s extra-scolaires | 'yes' ou 'no' |
| **nursery** | Binaire | A fr√©quent√© une cr√®che/maternelle | 'yes' ou 'no' |
| **higher** | Binaire | Veut poursuivre des √©tudes sup√©rieures | 'yes' ou 'no' |

### 7Ô∏è‚É£ Facteurs Technologiques et Sociaux (2 variables)

| Variable | Type | Description | Valeurs possibles |
|----------|------|-------------|-------------------|
| **internet** | Binaire | Acc√®s internet √† domicile | 'yes' ou 'no' |
| **romantic** | Binaire | En couple (relation romantique) | 'yes' ou 'no' |

### 8Ô∏è‚É£ Bien-√™tre et Relations (4 variables)

| Variable | Type | Description | Valeurs possibles |
|----------|------|-------------|-------------------|
| **famrel** | Num√©rique | Qualit√© des relations familiales | 1 (tr√®s mauvaise) √† 5 (excellente) |
| **freetime** | Num√©rique | Temps libre apr√®s l'√©cole | 1 (tr√®s faible) √† 5 (tr√®s √©lev√©) |
| **goout** | Num√©rique | Fr√©quence des sorties avec amis | 1 (tr√®s faible) √† 5 (tr√®s √©lev√©e) |
| **health** | Num√©rique | √âtat de sant√© actuel | 1 (tr√®s mauvais) √† 5 (tr√®s bon) |

### 9Ô∏è‚É£ Comportements √† Risque (2 variables)

| Variable | Type | Description | Valeurs possibles |
|----------|------|-------------|-------------------|
| **Dalc** | Num√©rique | Consommation d'alcool en semaine | 1 (tr√®s faible) √† 5 (tr√®s √©lev√©e) |
| **Walc** | Num√©rique | Consommation d'alcool le week-end | 1 (tr√®s faible) √† 5 (tr√®s √©lev√©e) |

### üîü Assiduit√© (1 variable)

| Variable | Type | Description | Valeurs possibles |
|----------|------|-------------|-------------------|
| **absences** | Num√©rique | Nombre d'absences scolaires | 0 √† 93 |

### 1Ô∏è‚É£1Ô∏è‚É£ Variables Cibles - Notes (3 variables)

| Variable | Type | Description | Valeurs possibles |
|----------|------|-------------|-------------------|
| **G1** | Num√©rique | Note de la 1√®re p√©riode | 0 √† 20 |
| **G2** | Num√©rique | Note de la 2√®me p√©riode | 0 √† 20 |
| **G3** | Num√©rique | **NOTE FINALE** (cible principale) | 0 √† 20 |

---

## üéØ Cas d'Usage et Applications

### T√¢ches de Machine Learning

#### 1. R√©gression
**Objectif :** Pr√©dire la note finale (G3) sur une √©chelle continue (0-20)

**Applications :**
- Pr√©diction pr√©cise des r√©sultats finaux
- Identification des √©tudiants n√©cessitant un soutien
- Estimation de l'impact de chaque facteur sur la performance

**M√©triques d'√©valuation :**
- RMSE (Root Mean Squared Error)
- MAE (Mean Absolute Error)
- R¬≤ Score

#### 2. Classification Binaire
**Objectif :** Pr√©dire si un √©tudiant va r√©ussir (G3 ‚â• 10) ou √©chouer (G3 < 10)

**Applications :**
- Syst√®me d'alerte pr√©coce pour √©checs scolaires
- Allocation des ressources de soutien
- Intervention cibl√©e

**M√©triques d'√©valuation :**
- Accuracy
- Precision/Recall
- F1-Score
- ROC-AUC

#### 3. Classification Multi-classes
**Objectif :** Classer les √©tudiants en 5 niveaux de performance

**Niveaux sugg√©r√©s :**
- √âchec : 0-9
- Passable : 10-11
- Moyen : 12-13
- Bien : 14-16
- Excellent : 17-20

**Applications :**
- Segmentation des √©tudiants
- Programmes d'enseignement diff√©renci√©
- √âvaluation comparative

**M√©triques d'√©valuation :**
- Accuracy
- Confusion Matrix
- Classification Report

---

## üìà Analyses Possibles

### Analyses Descriptives

1. **Distribution des notes**
   - Histogrammes G1, G2, G3
   - Statistiques (moyenne, m√©diane, √©cart-type)
   - Identification de patterns (bimodalit√©, asym√©trie)

2. **Analyse d√©mographique**
   - Performance par sexe
   - Impact de l'√¢ge
   - Diff√©rences urbain vs rural

3. **Facteurs socio-√©conomiques**
   - Corr√©lation √©ducation parentale / performance
   - Impact du type d'emploi parental
   - Effet du statut familial (parents ensemble/s√©par√©s)

4. **Comportements et habitudes**
   - Temps d'√©tude vs r√©sultats
   - Impact des activit√©s extra-scolaires
   - Effet de la consommation d'alcool
   - Relations amoureuses et performance

### Analyses Pr√©dictives

1. **Feature Importance**
   - Quels facteurs pr√©disent le mieux G3 ?
   - Poids relatifs des variables
   - Interactions entre features

2. **Mod√®les de Machine Learning**
   - R√©gression lin√©aire / Ridge / Lasso
   - Decision Trees / Random Forest
   - Gradient Boosting (XGBoost, LightGBM)
   - Support Vector Machines
   - Neural Networks

3. **Sc√©narios de pr√©diction**
   - **Sc√©nario 1 :** Pr√©dire G3 avec G1 et G2 (facile, corr√©lation forte)
   - **Sc√©nario 2 :** Pr√©dire G3 sans G1 et G2 (difficile, plus utile pratiquement)
   - **Sc√©nario 3 :** Pr√©dire G1 en d√©but d'ann√©e (intervention pr√©coce)

### Analyses Causales

1. **Impact des interventions**
   - Effet du support scolaire (schoolsup)
   - Impact des cours payants (paid)
   - R√¥le du soutien familial (famsup)

2. **Facteurs modifiables vs non-modifiables**
   - Non-modifiables : sexe, √¢ge, √©ducation parentale
   - Modifiables : temps d'√©tude, absences, consommation alcool
   - Recommandations actionnables pour am√©liorer performance

---

## üí° Insights et Hypoth√®ses

### Hypoth√®ses √† Tester

1. **√âducation parentale**
   - **H1 :** Plus l'√©ducation des parents est √©lev√©e, meilleure est la performance de l'√©tudiant
   - **Justification :** Capital culturel, valorisation de l'√©ducation

2. **Temps d'√©tude**
   - **H2 :** Plus de temps d'√©tude = meilleures notes (relation non-lin√©aire possible)
   - **Nuance :** Au-del√† d'un seuil, rendements d√©croissants

3. **√âchecs pass√©s**
   - **H3 :** Les √©checs pass√©s sont le meilleur pr√©dicteur d'√©checs futurs
   - **Implication :** Besoin d'interventions intensives pour ces √©tudiants

4. **Consommation d'alcool**
   - **H4 :** Corr√©lation n√©gative entre consommation alcool et performance
   - **Distinction :** Alcool en semaine (Dalc) plus impactant que week-end (Walc)

5. **Relations amoureuses**
   - **H5 :** √ätre en couple peut affecter n√©gativement la performance (distraction)
   - **Alternative :** Peut avoir effet positif (bien-√™tre √©motionnel)

6. **Acc√®s internet**
   - **H6 :** Acc√®s internet = meilleures notes (ressources √©ducatives)
   - **Nuance :** Peut aussi √™tre source de distraction

7. **Support scolaire**
   - **H7 :** Paradoxe possible - √©tudiants avec support scolaire ont notes plus basses
   - **Explication :** Support donn√© √† ceux en difficult√© (biais de s√©lection)

### Patterns Attendus

1. **Effet cumulatif**
   - Les difficult√©s s'accumulent : √©checs ‚Üí baisse motivation ‚Üí plus d'absences ‚Üí plus d'√©checs

2. **Facteurs de r√©silience**
   - Famille supportive + ambitions sup√©rieures = facteur protecteur contre √©checs

3. **Multiplicateurs**
   - √âducation parentale √©lev√©e + acc√®s internet + support familial = effets synergiques

---

## üõ†Ô∏è Guide Pratique d'Utilisation

### Installation et Chargement

#### M√©thode 1 : Via ucimlrepo (Recommand√©)

```python
# Installation
pip install ucimlrepo

# Chargement
from ucimlrepo import fetch_ucirepo

# R√©cup√©ration du dataset
student_performance = fetch_ucirepo(id=320)

# Acc√®s aux donn√©es
X = student_performance.data.features  # Features
y = student_performance.data.targets   # Target (G3)

# M√©tadonn√©es
print(student_performance.metadata)

# Information sur les variables
print(student_performance.variables)
```

#### M√©thode 2 : T√©l√©chargement Manuel

```python
import pandas as pd
import zipfile
import requests

# T√©l√©charger le fichier
url = "https://archive.ics.uci.edu/static/public/320/student+performance.zip"
response = requests.get(url)

# Sauvegarder et d√©compresser
with open("student_performance.zip", "wb") as f:
    f.write(response.content)

with zipfile.ZipFile("student_performance.zip", "r") as zip_ref:
    zip_ref.extractall("student_data")

# Charger les datasets
df_mat = pd.read_csv("student_data/student-mat.csv", sep=";")
df_por = pd.read_csv("student_data/student-por.csv", sep=";")

print(f"Math√©matiques : {df_mat.shape}")
print(f"Portugais : {df_por.shape}")
```

### Pr√©paration des Donn√©es

```python
import pandas as pd
import numpy as np
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.model_selection import train_test_split

# Charger les donn√©es (exemple avec Maths)
df = pd.read_csv("student-mat.csv", sep=";")

# 1. Encoder les variables cat√©gorielles
label_encoders = {}
categorical_columns = ['school', 'sex', 'address', 'famsize', 'Pstatus',
                       'Mjob', 'Fjob', 'reason', 'guardian',
                       'schoolsup', 'famsup', 'paid', 'activities',
                       'nursery', 'higher', 'internet', 'romantic']

for col in categorical_columns:
    le = LabelEncoder()
    df[col] = le.fit_transform(df[col])
    label_encoders[col] = le

# 2. S√©parer features et target
# Sc√©nario 1 : Avec G1 et G2
X_with_grades = df.drop(['G3'], axis=1)
y = df['G3']

# Sc√©nario 2 : Sans G1 et G2 (plus r√©aliste)
X_without_grades = df.drop(['G1', 'G2', 'G3'], axis=1)

# 3. Split train/test
X_train, X_test, y_train, y_test = train_test_split(
    X_without_grades, y, test_size=0.2, random_state=42
)

# 4. Normalisation (optionnel mais recommand√©)
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

print(f"Train set : {X_train.shape}")
print(f"Test set : {X_test.shape}")
```

### Exemple de Mod√©lisation Compl√®te

```python
from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor
from sklearn.linear_model import Ridge
from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error
import matplotlib.pyplot as plt

# 1. Plusieurs mod√®les √† comparer
models = {
    'Ridge Regression': Ridge(alpha=1.0),
    'Random Forest': RandomForestRegressor(n_estimators=100, random_state=42),
    'Gradient Boosting': GradientBoostingRegressor(n_estimators=100, random_state=42)
}

# 2. Entra√Ænement et √©valuation
results = {}

for name, model in models.items():
    # Entra√Ænement
    model.fit(X_train_scaled, y_train)

    # Pr√©dictions
    y_pred_train = model.predict(X_train_scaled)
    y_pred_test = model.predict(X_test_scaled)

    # M√©triques
    results[name] = {
        'train_r2': r2_score(y_train, y_pred_train),
        'test_r2': r2_score(y_test, y_pred_test),
        'test_rmse': np.sqrt(mean_squared_error(y_test, y_pred_test)),
        'test_mae': mean_absolute_error(y_test, y_pred_test)
    }

    print(f"\n{name}:")
    print(f"  Train R¬≤: {results[name]['train_r2']:.4f}")
    print(f"  Test R¬≤: {results[name]['test_r2']:.4f}")
    print(f"  Test RMSE: {results[name]['test_rmse']:.4f}")
    print(f"  Test MAE: {results[name]['test_mae']:.4f}")

# 3. Feature Importance (Random Forest)
rf_model = models['Random Forest']
feature_importance = pd.DataFrame({
    'feature': X_train.columns,
    'importance': rf_model.feature_importances_
}).sort_values('importance', ascending=False)

print("\nTop 10 Features les plus importantes:")
print(feature_importance.head(10))

# 4. Visualisation
plt.figure(figsize=(12, 6))
plt.barh(feature_importance.head(10)['feature'],
         feature_importance.head(10)['importance'])
plt.xlabel('Importance')
plt.title('Top 10 Features - Random Forest')
plt.tight_layout()
plt.savefig('feature_importance.png', dpi=300, bbox_inches='tight')
plt.show()
```

---

## üìä Analyses Exploratoires

### 1. Analyse Univari√©e

```python
import seaborn as sns
import matplotlib.pyplot as plt

# Distribution des notes finales
fig, axes = plt.subplots(1, 3, figsize=(15, 5))

axes[0].hist(df['G1'], bins=20, color='skyblue', edgecolor='black', alpha=0.7)
axes[0].set_title('Distribution G1 (1√®re p√©riode)', fontweight='bold')
axes[0].set_xlabel('Note')
axes[0].set_ylabel('Fr√©quence')

axes[1].hist(df['G2'], bins=20, color='lightgreen', edgecolor='black', alpha=0.7)
axes[1].set_title('Distribution G2 (2√®me p√©riode)', fontweight='bold')
axes[1].set_xlabel('Note')

axes[2].hist(df['G3'], bins=20, color='salmon', edgecolor='black', alpha=0.7)
axes[2].set_title('Distribution G3 (Finale)', fontweight='bold')
axes[2].set_xlabel('Note')

plt.tight_layout()
plt.savefig('distribution_notes.png', dpi=300, bbox_inches='tight')
plt.show()

# Statistiques descriptives
print("\n=== STATISTIQUES DESCRIPTIVES DES NOTES ===")
print(df[['G1', 'G2', 'G3']].describe())

# Taux de r√©ussite (G3 >= 10)
success_rate = (df['G3'] >= 10).mean() * 100
print(f"\nTaux de r√©ussite global: {success_rate:.2f}%")
```

### 2. Analyse Bivari√©e

```python
# Corr√©lations entre variables num√©riques
numerical_cols = df.select_dtypes(include=[np.number]).columns
correlation_matrix = df[numerical_cols].corr()

plt.figure(figsize=(16, 14))
sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0,
            fmt='.2f', square=True, linewidths=0.5)
plt.title('Matrice de Corr√©lation - Toutes Variables Num√©riques',
          fontsize=16, fontweight='bold', pad=20)
plt.tight_layout()
plt.savefig('correlation_matrix.png', dpi=300, bbox_inches='tight')
plt.show()

# Focus sur G3
g3_correlations = correlation_matrix['G3'].sort_values(ascending=False)
print("\n=== CORR√âLATIONS AVEC G3 (Note Finale) ===")
print(g3_correlations)

# Visualisation des top corr√©lations
plt.figure(figsize=(10, 8))
g3_correlations[1:11].plot(kind='barh', color='steelblue')
plt.title('Top 10 Corr√©lations avec G3', fontweight='bold', fontsize=14)
plt.xlabel('Coefficient de Corr√©lation')
plt.axvline(x=0, color='red', linestyle='--', alpha=0.5)
plt.tight_layout()
plt.savefig('top_correlations_g3.png', dpi=300, bbox_inches='tight')
plt.show()
```

### 3. Analyses par Groupes

```python
# Performance par sexe
fig, axes = plt.subplots(2, 2, figsize=(14, 10))

# Sexe
df.boxplot(column='G3', by='sex', ax=axes[0, 0])
axes[0, 0].set_title('Performance (G3) par Sexe')
axes[0, 0].set_xlabel('Sexe (F=Female, M=Male)')
axes[0, 0].set_ylabel('Note Finale (G3)')
plt.sca(axes[0, 0])
plt.xticks([1, 2], ['Female', 'Male'])

# √âducation de la m√®re
df.boxplot(column='G3', by='Medu', ax=axes[0, 1])
axes[0, 1].set_title('Performance selon √âducation M√®re')
axes[0, 1].set_xlabel('Niveau √âducation M√®re (0-4)')
axes[0, 1].set_ylabel('Note Finale (G3)')

# Temps d'√©tude
df.boxplot(column='G3', by='studytime', ax=axes[1, 0])
axes[1, 0].set_title('Performance selon Temps d\'√âtude')
axes[1, 0].set_xlabel('Temps √âtude (1:<2h, 2:2-5h, 3:5-10h, 4:>10h)')
axes[1, 0].set_ylabel('Note Finale (G3)')

# √âchecs pass√©s
df.boxplot(column='G3', by='failures', ax=axes[1, 1])
axes[1, 1].set_title('Performance selon √âchecs Pass√©s')
axes[1, 1].set_xlabel('Nombre d\'√âchecs Pass√©s')
axes[1, 1].set_ylabel('Note Finale (G3)')

plt.suptitle('')
plt.tight_layout()
plt.savefig('performance_by_groups.png', dpi=300, bbox_inches='tight')
plt.show()
```

### 4. Analyse Multivari√©e

```python
# Scatter plot matrix pour variables cl√©s
key_vars = ['G3', 'studytime', 'failures', 'absences', 'Medu', 'Fedu', 'age']
sns.pairplot(df[key_vars], diag_kind='kde', plot_kws={'alpha': 0.6})
plt.suptitle('Relations entre Variables Cl√©s', y=1.02, fontsize=16, fontweight='bold')
plt.savefig('pairplot_key_vars.png', dpi=300, bbox_inches='tight')
plt.show()

# Impact combin√© de plusieurs facteurs
fig, axes = plt.subplots(2, 2, figsize=(15, 12))

# √âducation parents vs G3
axes[0, 0].scatter(df['Medu'], df['G3'], alpha=0.5, s=50, c='blue', label='M√®re', edgecolors='black', linewidth=0.5)
axes[0, 0].scatter(df['Fedu'], df['G3'], alpha=0.5, s=50, c='red', label='P√®re', edgecolors='black', linewidth=0.5)
axes[0, 0].set_xlabel('Niveau √âducation Parentale (0-4)', fontweight='bold')
axes[0, 0].set_ylabel('Note Finale (G3)', fontweight='bold')
axes[0, 0].set_title('√âducation Parentale vs Performance', fontweight='bold', fontsize=12)
axes[0, 0].legend()
axes[0, 0].grid(alpha=0.3)

# √âchecs pass√©s vs G3
axes[0, 1].scatter(df['failures'], df['G3'], alpha=0.5, s=50, color='green', edgecolors='black', linewidth=0.5)
axes[0, 1].set_xlabel('Nombre d\'√âchecs Pass√©s', fontweight='bold')
axes[0, 1].set_ylabel('Note Finale (G3)', fontweight='bold')
axes[0, 1].set_title('√âchecs Pass√©s vs Performance', fontweight='bold', fontsize=12)
axes[0, 1].grid(alpha=0.3)

# Absences vs G3
axes[1, 0].scatter(df['absences'], df['G3'], alpha=0.5, s=50, color='orange', edgecolors='black', linewidth=0.5)
axes[1, 0].set_xlabel('Nombre d\'Absences', fontweight='bold')
axes[1, 0].set_ylabel('Note Finale (G3)', fontweight='bold')
axes[1
[student-performance-analysis.md](https://github.com/user-attachments/files/23503178/student-performance-analysis.md)

# Installation
!pip install ucimlrepo

# Chargement
from ucimlrepo import fetch_ucirepo

# R√©cup√©ration du dataset
student_performance = fetch_ucirepo(id=320)

# Acc√®s aux donn√©es
X = student_performance.data.features  # Features
y = student_performance.data.targets   # Target (G3)

# M√©tadonn√©es
print(student_performance.metadata)

# Information sur les variables
print(student_performance.variables)

# ============================================================
# üìä ANALYSE EXPLORATOIRE DU DATASET STUDENT PERFORMANCE (UCI)
# ============================================================

# === 1. Importation des biblioth√®ques ===
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error
import os

# === 2. Chargement des donn√©es ===
# Instead of downloading again, load from the locally extracted files
extraction_dir = "student_data"
df_mat = pd.read_csv(os.path.join(extraction_dir, "student-mat.csv"), sep=";")
df_por = pd.read_csv(os.path.join(extraction_dir, "student-por.csv"), sep=";")

# On utilisera ici les donn√©es de math√©matiques
df = df_mat.copy()
print(f"Dimensions : {df.shape}")
print(df.head())

# === 3. Encodage des variables cat√©gorielles ===
categorical_cols = df.select_dtypes(include=['object']).columns
label_encoders = {}
for col in categorical_cols:
    le = LabelEncoder()
    df[col] = le.fit_transform(df[col])
    label_encoders[col] = le

# === 4. Statistiques descriptives ===
print("\n=== Statistiques descriptives des notes ===")
print(df[['G1', 'G2', 'G3']].describe())

# === 5. Histogrammes des notes ===
plt.figure(figsize=(15, 4))
for i, g in enumerate(['G1', 'G2', 'G3']):
    plt.subplot(1, 3, i+1)
    plt.hist(df[g], bins=20, color=sns.color_palette("husl")[i], edgecolor='black', alpha=0.7)
    plt.title(f"Distribution {g}", fontsize=12, fontweight='bold')
    plt.xlabel("Note")
    plt.ylabel("Fr√©quence")
plt.tight_layout()
plt.show()

# === 6. Matrice de corr√©lation ===
plt.figure(figsize=(16, 14))
corr = df.corr()
sns.heatmap(corr, cmap="coolwarm", center=0, annot=False)
plt.title("Matrice de Corr√©lation - Toutes Variables", fontsize=16, fontweight="bold")
plt.show()

# === 7. Corr√©lation avec la note finale (G3) ===
g3_corr = corr['G3'].sort_values(ascending=False)
print("\nTop 10 corr√©lations avec G3 :\n", g3_corr.head(10))

plt.figure(figsize=(10, 6))
g3_corr[1:11].plot(kind='barh', color='steelblue')
plt.title('Top 10 corr√©lations avec la note finale (G3)', fontsize=14, fontweight='bold')
plt.xlabel('Coefficient de corr√©lation')
plt.tight_layout()
plt.show()

# === 8. Boxplots de performance par groupe ===
fig, axes = plt.subplots(2, 2, figsize=(14, 10))

# Sexe
sns.boxplot(x='sex', y='G3', data=df, ax=axes[0, 0])
axes[0, 0].set_title('Performance selon le sexe')

# √âducation de la m√®re
sns.boxplot(x='Medu', y='G3', data=df, ax=axes[0, 1])
axes[0, 1].set_title('Performance selon √©ducation de la m√®re')

# Temps d‚Äô√©tude
sns.boxplot(x='studytime', y='G3', data=df, ax=axes[1, 0])
axes[1, 0].set_title('Performance selon temps d‚Äô√©tude')

# Nombre d‚Äô√©checs
sns.boxplot(x='failures', y='G3', data=df, ax=axes[1, 1])
axes[1, 1].set_title('Performance selon √©checs pass√©s')

plt.tight_layout()
plt.show()

# === 9. Analyse multivari√©e ===
key_vars = ['G3', 'studytime', 'failures', 'absences', 'Medu', 'Fedu', 'age']
sns.pairplot(df[key_vars], diag_kind='kde', plot_kws={'alpha': 0.5})
plt.suptitle('Relations entre variables cl√©s', y=1.02, fontsize=16, fontweight='bold')
plt.show()

# === 10. Mod√©lisation simple (Random Forest) ===
X = df.drop(['G3'], axis=1)
y = df['G3']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

rf = RandomForestRegressor(n_estimators=100, random_state=42)
rf.fit(X_train_scaled, y_train)
y_pred = rf.predict(X_test_scaled)

print("\n=== R√©sultats du mod√®le Random Forest ===")
print("R¬≤ :", r2_score(y_test, y_pred))
print("RMSE :", np.sqrt(mean_squared_error(y_test, y_pred)))
print("MAE :", mean_absolute_error(y_test, y_pred))

# === 11. Importance des variables ===
feature_importance = pd.DataFrame({
    'feature': X.columns,
    'importance': rf.feature_importances_
}).sort_values('importance', ascending=False)

plt.figure(figsize=(10, 6))
sns.barplot(data=feature_importance.head(10), x='importance', y='feature', palette='viridis')
plt.title('Top 10 variables les plus importantes - Random Forest', fontsize=14, fontweight='bold')
plt.tight_layout()
plt.show()

# === 12. Sauvegarde des graphiques (optionnel) ===
# plt.savefig('student_performance_EDA.png', dpi=300)

import pandas as pd
import zipfile
import requests
import os

# T√©l√©charger le fichier
url = "https://archive.ics.uci.edu/static/public/320/student+performance.zip"
response = requests.get(url)

# Sauvegarder le fichier zip t√©l√©charg√©
zip_filename = "student_performance.zip"
with open(zip_filename, "wb") as f:
    f.write(response.content)

# Cr√©er le r√©pertoire pour l'extraction si il n'existe pas
extraction_dir = "student_data"
os.makedirs(extraction_dir, exist_ok=True)

# 1. D√©compresser le fichier principal (student_performance.zip)
# Il semble que ce zip contient un autre zip nomm√© "student.zip" ou un dossier "student"
with zipfile.ZipFile(zip_filename, "r") as zip_ref:
    zip_ref.extractall(extraction_dir)

# --- Diagnostic Step: List directory contents after first extraction ---
print(f"Contents of '{extraction_dir}' after first extraction:")
!ls -R {extraction_dir}
print("---------------------------------------------------")

# V√©rifier si le zip interne "student.zip" existe
inner_zip_path = os.path.join(extraction_dir, "student.zip")

if os.path.exists(inner_zip_path):
    print("Found nested 'student.zip'. Extracting its contents...")
    # 2. D√©compresser le fichier interne (student.zip)
    with zipfile.ZipFile(inner_zip_path, "r") as inner_zip_ref:
        inner_zip_ref.extractall(extraction_dir) # Extract to the same dir, it should create 'student/'

    print(f"Contents of '{extraction_dir}' after second extraction:")
    !ls -R {extraction_dir}
    print("---------------------------------------------------")


# Charger les datasets avec les chemins corrig√©s
# Les fichiers sont maintenant directement dans 'student_data/'
df_mat = pd.read_csv(os.path.join(extraction_dir, "student-mat.csv"), sep=";")
df_por = pd.read_csv(os.path.join(extraction_dir, "student-por.csv"), sep=";")

print(f"Math√©matiques : {df_mat.shape}")
print(f"Portugais : {df_por.shape}")