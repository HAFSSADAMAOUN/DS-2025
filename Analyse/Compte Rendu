# Analyse des Rapports de CriminalitÃ© au BrÃ©sil

## ğŸ“‹ Table des MatiÃ¨res
1. [Introduction](#introduction)
2. [Configuration de l'Environnement](#configuration)
3. [Chargement et PrÃ©paration des DonnÃ©es](#chargement)
4. [Analyse Exploratoire](#analyse-exploratoire)
5. [ModÃ©lisation](#modelisation)
6. [RÃ©sultats et Conclusions](#conclusions)

---

## 1. Introduction {#introduction}

### Contexte du Projet
Cette analyse porte sur les donnÃ©es de rapports de criminalitÃ© au BrÃ©sil, couvrant la pÃ©riode 2022-2024. L'objectif est d'explorer les tendances, patterns et caractÃ©ristiques des incidents criminels rapportÃ©s.

### Objectifs
- Comprendre la distribution temporelle des incidents
- Analyser l'Ã©volution des versions de rapports
- DÃ©velopper des modÃ¨les prÃ©dictifs
- Identifier les patterns significatifs

### Source des DonnÃ©es
- **Source**: Kaggle - Brazilian Crime Reports Dataset
- **PÃ©riode**: 2022-2024
- **Format**: CSV (espace comme dÃ©limiteur)

---

## 2. Configuration de l'Environnement {#configuration}

### BibliothÃ¨ques Requises
```python
# Gestion des avertissements
import warnings
warnings.filterwarnings('ignore')

# Manipulation de donnÃ©es
import numpy as np
import pandas as pd

# Visualisation
import matplotlib
matplotlib.use('Agg')
import matplotlib.pyplot as plt
plt.switch_backend('Agg')
import seaborn as sns

# Configuration
%matplotlib inline
sns.set(style='whitegrid')
```

### Configuration de l'Environnement Visuel
- **Style Seaborn**: `whitegrid` pour une meilleure lisibilitÃ©
- **Backend Matplotlib**: `Agg` pour l'exportation
- **IntÃ©gration**: Mode inline pour Jupyter

---

## 3. Chargement et PrÃ©paration des DonnÃ©es {#chargement}

### 3.1 Structure des DonnÃ©es

Les donnÃ©es sont rÃ©parties sur **trois fichiers CSV** (un par annÃ©e) :
- `data_2022.csv`
- `data_2023.csv`
- `data_2024.csv`

### 3.2 Fonction de Chargement
```python
def load_and_augment(filename, year):
    """
    Charge un fichier CSV et ajoute une colonne 'year'.
    
    ParamÃ¨tres:
    -----------
    filename : str
        Chemin du fichier CSV
    year : str
        AnnÃ©e Ã  ajouter comme colonne
    
    Returns:
    --------
    pd.DataFrame
        DataFrame avec colonne 'year' ajoutÃ©e
    """
    try:
        df = pd.read_csv(filename, delimiter=' ', encoding='ascii')
        df['year'] = year
        return df
    except Exception as e:
        print(f"Erreur lors du chargement de {filename}: {e}")
        return pd.DataFrame()
```

### 3.3 Chargement et Consolidation
```python
# Chargement des donnÃ©es annuelles
df_2022 = load_and_augment('data_2022.csv', '2022')
df_2023 = load_and_augment('data_2023.csv', '2023')
df_2024 = load_and_augment('data_2024.csv', '2024')

# Consolidation
df = pd.concat([df_2022, df_2023, df_2024], ignore_index=True)

print(f'Dimensions du DataFrame: {df.shape}')
print(f'Colonnes: {df.columns.tolist()}')
```

**RÃ©sultat:**
```
Dimensions du DataFrame: (9, 3)
Colonnes: ['version', 'url_column', 'year']
```

### 3.4 Nettoyage des DonnÃ©es
```python
# VÃ©rification des valeurs manquantes
if 'version' in df.columns:
    print(f'Valeurs manquantes (version): {df["version"].isnull().sum()}')
    df['version'] = df['version'].fillna("")

if 'year' in df.columns:
    print(f'Valeurs manquantes (year): {df["year"].isnull().sum()}')
    df['year'] = df['year'].astype('category')
```

**AperÃ§u des donnÃ©es nettoyÃ©es:**
```python
df.head()
```

| version | url_column | year |
|---------|-----------|------|
| v1.0 | http://example.com/2022_a | 2022 |
| v1.1 | http://example.com/2022_b | 2022 |
| v1.0 | http://example.com/2022_c | 2022 |
| v1.1 | http://example.com/2023_a | 2023 |
| v1.2 | http://example.com/2023_b | 2023 |

---

## 4. Analyse Exploratoire {#analyse-exploratoire}

### 4.1 Distribution Temporelle
```python
if 'year' in df.columns and not df['year'].empty:
    fig, ax = plt.subplots(figsize=(8, 4))
    sns.countplot(x='year', data=df, palette='viridis', ax=ax)
    ax.set_title('Distribution des Rapports par AnnÃ©e')
    ax.set_xlabel('AnnÃ©e')
    ax.set_ylabel('Nombre de Rapports')
    plt.tight_layout()
    plt.show()
```

![Distribution par AnnÃ©e](attachment:count_by_year.png)

**Observations:**
- âœ… Distribution **Ã©quilibrÃ©e** sur les 3 annÃ©es
- ğŸ“Š **3 rapports** par annÃ©e (2022, 2023, 2024)
- ğŸ“ˆ Aucune tendance temporelle apparente dans ce dataset limitÃ©

### 4.2 Distribution des Versions
```python
if 'version' in df.columns and not df['version'].empty:
    fig, ax = plt.subplots(figsize=(10, 4))
    sns.countplot(x='version', data=df, palette='magma', ax=ax)
    ax.set_title('Distribution des Versions de Rapports')
    ax.set_xlabel('Version')
    ax.set_ylabel('FrÃ©quence')
    plt.xticks(rotation=45)
    plt.tight_layout()
    plt.show()
```

![Distribution par Version](attachment:count_by_version.png)

**Statistiques des Versions:**

| Version | Nombre | Pourcentage |
|---------|--------|-------------|
| v1.1 | 3 | 33.3% |
| v1.2 | 3 | 33.3% |
| v1.0 | 2 | 22.2% |
| v1.3 | 1 | 11.1% |

**Insights:**
- ğŸ” Versions **v1.1** et **v1.2** les plus frÃ©quentes
- ğŸ“‰ Version **v1.3** la moins utilisÃ©e
- ğŸ”„ Ã‰volution progressive des versions

### 4.3 Informations Structurelles
```python
df.info()
```
```
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 9 entries, 0 to 8
Data columns (total 3 columns):
 #   Column      Non-Null Count  Dtype   
---  ------      --------------  -----   
 0   version     9 non-null      object  
 1   url_column  9 non-null      object  
 2   year        9 non-null      category
dtypes: category(1), object(2)
memory usage: 417.0+ bytes
```

**Points clÃ©s:**
- âœ… **Aucune valeur manquante**
- ğŸ“Š **9 observations** complÃ¨tes
- ğŸ’¾ Utilisation mÃ©moire optimisÃ©e (417 bytes)

---

## 5. ModÃ©lisation {#modelisation}

### 5.1 CrÃ©ation de la Variable Cible

Pour permettre une analyse prÃ©dictive, nous crÃ©ons une variable cible synthÃ©tique :
```python
# Mapping des versions
version_mapping = {
    'v1.0': 1, 
    'v1.1': 2, 
    'v1.2': 3, 
    'v1.3': 4
}

df['mapped_version'] = df['version'].map(version_mapping)

# CrÃ©ation de la cible synthÃ©tique
df['synthetic_target'] = (df['year'].astype(int) - 2022) * 10 + df['mapped_version']
```

**AperÃ§u de la variable cible:**
```python
df[['version', 'year', 'synthetic_target']].head()
```

| version | year | synthetic_target |
|---------|------|------------------|
| v1.0 | 2022 | 1 |
| v1.1 | 2022 | 2 |
| v1.0 | 2022 | 1 |
| v1.1 | 2023 | 12 |
| v1.2 | 2023 | 13 |

### 5.2 PrÃ©paration des Features
```python
from sklearn.model_selection import train_test_split

# Encodage one-hot
X = pd.get_dummies(
    df[['version', 'year']], 
    columns=['version', 'year'], 
    drop_first=True
)

y = df['synthetic_target']

# Split train/test (80/20)
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)
```

**Dimensions:**
- ğŸ“Š Features (X): `(9, 5)`
- ğŸ¯ Target (y): `(9,)`
- ğŸ“ Training set: `(7, 5)`
- ğŸ§ª Test set: `(2, 5)`

### 5.3 RÃ©gression LinÃ©aire
```python
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error, r2_score

# EntraÃ®nement
model = LinearRegression()
model.fit(X_train, y_train)

# PrÃ©dictions
y_pred = model.predict(X_test)

# MÃ©triques
mse = mean_squared_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)

print(f"MSE: {mse:.2f}")
print(f"RÂ²: {r2:.2f}")
```

**RÃ©sultats:**
```
MSE: 70.31
RÂ²: 0.42
```

#### Visualisation des PrÃ©dictions
```python
plt.figure(figsize=(8, 6))
plt.scatter(y_test, y_pred, alpha=0.7, color='steelblue')
plt.plot([y.min(), y.max()], [y.min(), y.max()], 'r--', lw=2, label='PrÃ©diction parfaite')
plt.xlabel('Valeurs RÃ©elles')
plt.ylabel('Valeurs PrÃ©dites')
plt.title('RÃ©gression LinÃ©aire: RÃ©el vs PrÃ©dit')
plt.legend()
plt.grid(True, alpha=0.3)
plt.show()
```

![Scatter Plot](attachment:regression_plot.png)

### 5.4 RÃ©gression Logistique

Pour la classification, nous crÃ©ons une variable binaire :
```python
# CrÃ©ation de la cible binaire
median_target = df['synthetic_target'].median()
df['binary_target'] = (df['synthetic_target'] >= median_target).astype(int)

print(f"MÃ©diane: {median_target}")
print(df['binary_target'].value_counts())
```
```
MÃ©diane: 12.0
1    6
0    3
```
```python
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix

# PrÃ©paration des donnÃ©es
X_log = pd.get_dummies(df[['version', 'year']], columns=['version', 'year'], drop_first=True)
y_log = df['binary_target']

X_train_log, X_test_log, y_train_log, y_test_log = train_test_split(
    X_log, y_log, test_size=0.2, random_state=42, stratify=y_log
)

# EntraÃ®nement
log_model = LogisticRegression(random_state=42, solver='liblinear')
log_model.fit(X_train_log, y_train_log)

# PrÃ©dictions
y_pred_log = log_model.predict(X_test_log)

# MÃ©triques
accuracy = accuracy_score(y_test_log, y_pred_log)
conf_matrix = confusion_matrix(y_test_log, y_pred_log)

print(f"Accuracy: {accuracy:.2f}")
print("\nMatrice de Confusion:")
print(conf_matrix)
```

**RÃ©sultats:**
```
Accuracy: 0.50

Matrice de Confusion:
[[0 1]
 [0 1]]
```

#### Visualisation de la Matrice de Confusion
```python
plt.figure(figsize=(6, 5))
sns.heatmap(
    conf_matrix, 
    annot=True, 
    fmt='d', 
    cmap='Blues',
    xticklabels=['Classe 0', 'Classe 1'],
    yticklabels=['Classe 0', 'Classe 1']
)
plt.xlabel('PrÃ©diction')
plt.ylabel('RÃ©alitÃ©')
plt.title('Matrice de Confusion - RÃ©gression Logistique')
plt.show()
```

![Confusion Matrix](attachment:confusion_matrix.png)

---

## 6. RÃ©sultats et Conclusions {#conclusions}

### ğŸ“Š RÃ©sultats ClÃ©s

#### DonnÃ©es
- âœ… **9 observations** consolidÃ©es (2022-2024)
- âœ… **Aucune valeur manquante**
- âœ… Distribution Ã©quilibrÃ©e temporellement
- âš ï¸ Dataset limitÃ© pour une analyse approfondie

#### Distributions
- ğŸ“ˆ Versions **v1.1** et **v1.2** dominent (33.3% chacune)
- ğŸ“‰ Version **v1.3** rare (11.1%)
- âš–ï¸ Ã‰quilibre parfait entre annÃ©es

#### Performance des ModÃ¨les

| ModÃ¨le | MÃ©trique | Score | InterprÃ©tation |
|--------|----------|-------|----------------|
| RÃ©gression LinÃ©aire | RÂ² | 0.42 | ModÃ©rÃ© |
| RÃ©gression LinÃ©aire | MSE | 70.31 | Ã‰levÃ© |
| RÃ©gression Logistique | Accuracy | 0.50 | Faible |

### ğŸ” Insights Principaux

1. **QualitÃ© des DonnÃ©es**
   - âœ… DonnÃ©es propres et structurÃ©es
   - âš ï¸ Volume insuffisant pour modÃ©lisation robuste
   - ğŸ“Š NÃ©cessite davantage d'observations

2. **ModÃ©lisation**
   - RÂ² = 0.42 â†’ Le modÃ¨le explique 42% de la variance
   - Accuracy = 0.50 â†’ Performance alÃ©atoire pour la classification
   - ğŸ¯ NÃ©cessite plus de features et d'observations

3. **Ã‰volution des Versions**
   - ğŸ”„ Progression cohÃ©rente (v1.0 â†’ v1.3)
   - ğŸ“ˆ Adoption progressive des nouvelles versions
   - ğŸ’¡ Potentiel pour analyse de migration

### âš ï¸ Limitations

1. **Volume de DonnÃ©es**
   - 9 observations trop limitÃ©es
   - Risque d'overfitting
   - GÃ©nÃ©ralisabilitÃ© compromise

2. **Features Disponibles**
   - Seulement 2 variables prÃ©dictives
   - Manque de contexte criminel
   - Information limitÃ©e

3. **Validation**
   - Split test/train dÃ©sÃ©quilibrÃ© (7/2)
   - Pas de cross-validation
   - MÃ©triques peu fiables

### ğŸ¯ Recommandations

#### Court Terme
1. **Collecter Plus de DonnÃ©es**
   - ğŸ“Š Viser minimum 100-200 observations
   - ğŸ”„ Ã‰largir la pÃ©riode temporelle
   - ğŸ“ Inclure donnÃ©es gÃ©ographiques

2. **Enrichir les Features**
   - ğŸ·ï¸ Type de crime
   - ğŸ“ Localisation gÃ©ographique
   - â° Horodatage prÃ©cis
   - ğŸ‘¥ DonnÃ©es dÃ©mographiques

3. **AmÃ©liorer la ModÃ©lisation**
   - âœ… Cross-validation k-fold
   - ğŸ¯ ModÃ¨les plus sophistiquÃ©s (Random Forest, XGBoost)
   - ğŸ“Š Analyse de sÃ©ries temporelles

#### Long Terme
1. **SystÃ¨me de Monitoring**
   - ğŸ“ˆ Tableau de bord temps rÃ©el
   - ğŸš¨ Alertes automatiques
   - ğŸ“Š KPIs criminels

2. **Analyse PrÃ©dictive**
   - ğŸ”® PrÃ©diction de hotspots
   - â° PrÃ©vision temporelle
   - ğŸ¯ Allocation optimale des ressources

3. **IntÃ©gration OpÃ©rationnelle**
   - ğŸ”— API de donnÃ©es en temps rÃ©el
   - ğŸ—ºï¸ Visualisation gÃ©ospatiale
   - ğŸ“± Application mobile

### ğŸ“š RÃ©fÃ©rences

- **Dataset**: [Kaggle - Brazilian Crime Reports](https://www.kaggle.com/code/devraai/brazilian-crime-reports-data-analysis/)
- **BibliothÃ¨ques**: pandas, scikit-learn, seaborn, matplotlib
- **MÃ©thodes**: RÃ©gression linÃ©aire, rÃ©gression logistique, one-hot encoding

---

## ğŸ“ Annexes

### Code Complet

Le code complet est disponible dans le notebook Jupyter :
`brazilian-crime-reports-data-analysis.ipynb`

### Environnement Technique

- **Python**: 3.8+
- **pandas**: 1.3+
- **scikit-learn**: 0.24+
- **matplotlib**: 3.3+
- **seaborn**: 0.11+

### Contact

Pour questions ou suggestions :
- ğŸ“§ Email: [votre-email]
- ğŸ’¼ LinkedIn: [votre-profil]
- ğŸ™ GitHub: [votre-repo]

---

*Rapport gÃ©nÃ©rÃ© le: 01/12/2025*
*Version: 1.0*
